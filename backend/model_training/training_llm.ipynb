{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1vyH4LVtfD6e1q_QbzEhB2t0PhY-Vy707","authorship_tag":"ABX9TyN+yUL0u8DR8yVmT5QWezoT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M8mG4GB2HDaL","executionInfo":{"status":"ok","timestamp":1729884127021,"user_tz":-120,"elapsed":10156,"user":{"displayName":"MELLIODAS 9","userId":"10772039741812287121"}},"outputId":"5a9e486e-e44b-4a1f-c0e6-abaf6a7e21db"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n","Collecting datasets\n","  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n","Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-3.0.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"]}],"source":["!pip install transformers torch datasets"]},{"cell_type":"code","source":["import kagglehub\n","\n","# Download latest version\n","path = kagglehub.dataset_download(\"wcukierski/enron-email-dataset\")\n","\n","print(\"Path to dataset files:\", path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MDmhLp_iJSBA","executionInfo":{"status":"ok","timestamp":1729884426200,"user_tz":-120,"elapsed":16499,"user":{"displayName":"MELLIODAS 9","userId":"10772039741812287121"}},"outputId":"3d17e6e6-db8f-4cb8-8b0c-c91915a8a074"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/datasets/download/wcukierski/enron-email-dataset?dataset_version_number=2...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 358M/358M [00:02<00:00, 150MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Path to dataset files: /root/.cache/kagglehub/datasets/wcukierski/enron-email-dataset/versions/2\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load emails from the CSV file in the dataset directory\n","data_path = \"/root/.cache/kagglehub/datasets/wcukierski/enron-email-dataset/versions/2/emails.csv\"\n","df = pd.read_csv(data_path)\n","\n","# Inspect the first few rows to understand the structure\n","print(df.head())\n","print(df.shape)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BO2FE2HaISH_","executionInfo":{"status":"ok","timestamp":1729890070456,"user_tz":-120,"elapsed":18968,"user":{"displayName":"MELLIODAS 9","userId":"10772039741812287121"}},"outputId":"e648eb00-05e3-4286-a9f8-7865578bd9c6"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["                       file                                            message\n","0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n","1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n","2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n","3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n","4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e...\n","(517401, 2)\n"]}]},{"cell_type":"code","source":["def prepare_summarization_data(text):\n","    return f\"summarize: {text}\"\n","\n","df['input_text'] = df['message'].apply(prepare_summarization_data)\n","df['target_text'] = df['message'].apply(lambda x: x[:int(len(x) * 0.5)])\n","dataset = df[['input_text', 'target_text']]\n"],"metadata":{"id":"l_vLjv1hJ5h3","executionInfo":{"status":"ok","timestamp":1729889762768,"user_tz":-120,"elapsed":5869,"user":{"displayName":"MELLIODAS 9","userId":"10772039741812287121"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from transformers import T5Tokenizer\n","\n","# Initialize tokenizer\n","tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n","\n","# Function to tokenize data\n","def tokenize_data(example):\n","    input_encodings = tokenizer(example['input_text'], truncation=True, padding=\"max_length\", max_length=512)\n","    target_encodings = tokenizer(example['target_text'], truncation=True, padding=\"max_length\", max_length=50)\n","    return {\n","        'input_ids': input_encodings['input_ids'],\n","        'attention_mask': input_encodings['attention_mask'],\n","        'labels': target_encodings['input_ids']\n","    }\n","\n","# Select the first 1000 data points\n","dataset_subset = dataset[:10000]\n","\n","# Apply tokenization\n","tokenized_dataset = dataset_subset.apply(tokenize_data, axis=1)\n"],"metadata":{"id":"CPaPGMP0J5pd","executionInfo":{"status":"ok","timestamp":1729893095351,"user_tz":-120,"elapsed":82127,"user":{"displayName":"MELLIODAS 9","userId":"10772039741812287121"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from transformers import Seq2SeqTrainingArguments\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"./results\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=3,\n","    predict_with_generate=True,\n","    fp16=True  # For mixed precision training on GPU\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ve9m7o6hq-uh","executionInfo":{"status":"ok","timestamp":1729893955589,"user_tz":-120,"elapsed":336,"user":{"displayName":"MELLIODAS 9","userId":"10772039741812287121"}},"outputId":"a7c94c93-ff7b-47c0-8659-b6fbbb18d7e6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["test_email = \"Long email text here for testing...\"\n","inputs = tokenizer(f\"summarize: {test_email}\", return_tensors=\"pt\")\n","summary_ids = model.generate(inputs['input_ids'], max_length=50, length_penalty=0.8, early_stopping=True)\n","summarized_email = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n","print(\"Summarized Email:\", summarized_email)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7ECM6JQq_Aw","executionInfo":{"status":"ok","timestamp":1729893985964,"user_tz":-120,"elapsed":783,"user":{"displayName":"MELLIODAS 9","userId":"10772039741812287121"}},"outputId":"0d6a043b-52fb-421e-dc82-4d173a70971a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:634: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `0.8` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Summarized Email: email text for testing...\n"]}]},{"cell_type":"code","source":["def footprint_score(text):\n","    return len(text.encode('utf-8'))\n","\n","print(\"Footprint score:\", footprint_score(summarized_email))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BqpL36YtuAZM","executionInfo":{"status":"ok","timestamp":1729894033765,"user_tz":-120,"elapsed":360,"user":{"displayName":"MELLIODAS 9","userId":"10772039741812287121"}},"outputId":"b773cd85-2fe2-46b8-a166-fa24c753fa37"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Footprint score: 25\n"]}]},{"cell_type":"code","source":["test_email = \"\"\"Subject: Project Update and Next Steps Body:\n","\n","Dear Team,\n","\n","I hope this message finds you well. I wanted to provide an update on the recent developments in our project and outline the next steps for everyone involved. We’ve made considerable progress over the last few weeks, and I’d like to thank each of you for your dedication and hard work.\n","\n","First, we have successfully completed Phase 1, which included market research and initial data collection. Our findings have shown promising insights that will inform the strategies we adopt in the subsequent phases. The data indicates a clear demand for our proposed solution, and it has helped us refine our target audience.\n","\n","Moving into Phase 2, our immediate objectives are as follows:\n","\n","Refine the product prototype based on the feedback gathered during Phase 1.\n","Conduct a series of usability tests to identify potential improvements.\n","Collaborate with the marketing team to begin outlining our initial outreach campaign.\n","For the usability tests, I’d like to remind everyone to document their findings in the shared project folder. Please include any relevant screenshots, participant feedback, and usability scores, as this will be invaluable for our development team. The testing phase is scheduled to last for two weeks, starting next Monday.\n","\n","Additionally, I want to ensure that everyone is on the same page regarding our upcoming deadlines. Here’s a quick rundown of our timeline:\n","\n","Prototype Refinement: Complete by the end of next week.\n","Usability Testing: Conducted over the following two weeks.\n","Initial Outreach Campaign Plan: Draft ready for review by the end of the month.\n","Please let me know if you have any questions or need further clarification on any of the points mentioned. I appreciate all your efforts and am confident that we’re on the right path to achieve our goals. Let’s continue to work together and keep up the momentum!\n","\n","Thank you, and looking forward to our next meeting on Friday.\n","\n","Best regards,\n","[Your Name]\n","Project Manager \"\"\"\n","inputs = tokenizer(f\"summarize: {test_email}\", return_tensors=\"pt\")\n","summary_ids = model.generate(inputs['input_ids'], max_length=50, length_penalty=0.8, early_stopping=True)\n","summarized_email = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n","print(\"Summarized Email:\", summarized_email)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VQjapTxEuAch","executionInfo":{"status":"ok","timestamp":1729894976958,"user_tz":-120,"elapsed":1505,"user":{"displayName":"MELLIODAS 9","userId":"10772039741812287121"}},"outputId":"43fdbfe8-351d-45d3-e7ed-067a686792b2"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Summarized Email: we have completed Phase 1, which included market research and initial data collection. the data indicates a clear demand for our proposed solution.\n"]}]},{"cell_type":"code","source":["print(\"Footprint score:\", footprint_score(summarized_email))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6OQBatQvq_LQ","executionInfo":{"status":"ok","timestamp":1729895120608,"user_tz":-120,"elapsed":279,"user":{"displayName":"MELLIODAS 9","userId":"10772039741812287121"}},"outputId":"7c713ce8-52af-4181-dc61-c6d9eb95546c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Footprint score: 147\n"]}]},{"cell_type":"code","source":["model.save_pretrained(\"/content/t5_model\")\n","tokenizer.save_pretrained(\"/content/t5_model\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zrb7FRL2yXTg","executionInfo":{"status":"ok","timestamp":1729903736387,"user_tz":-120,"elapsed":5394,"user":{"displayName":"MELLIODAS 9","userId":"10772039741812287121"}},"outputId":"92808545-7a45-44fb-9480-3d68c641252a"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/t5_model/tokenizer_config.json',\n"," '/content/t5_model/special_tokens_map.json',\n"," '/content/t5_model/spiece.model',\n"," '/content/t5_model/added_tokens.json')"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["!zip -r t5_model.zip /content/t5_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TyXWTGKnyX9o","executionInfo":{"status":"ok","timestamp":1729903945536,"user_tz":-120,"elapsed":72136,"user":{"displayName":"MELLIODAS 9","userId":"10772039741812287121"}},"outputId":"af75c6fd-b867-4f37-9235-f8375dd5f4d9"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/t5_model/ (stored 0%)\n","  adding: content/t5_model/added_tokens.json (deflated 83%)\n","  adding: content/t5_model/config.json (deflated 62%)\n","  adding: content/t5_model/special_tokens_map.json (deflated 85%)\n","  adding: content/t5_model/spiece.model (deflated 48%)\n","  adding: content/t5_model/generation_config.json (deflated 30%)\n","  adding: content/t5_model/tokenizer_config.json (deflated 94%)\n","  adding: content/t5_model/model.safetensors (deflated 53%)\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"t5_model.zip\")"],"metadata":{"id":"AIsKbp3HUGNx","executionInfo":{"status":"ok","timestamp":1729904017832,"user_tz":-120,"elapsed":326,"user":{"displayName":"MELLIODAS 9","userId":"10772039741812287121"}},"outputId":"f04970b3-e38c-458f-b9ca-67e0aa8f1229","colab":{"base_uri":"https://localhost:8080/","height":34}},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_9725d450-14fc-4369-8a9d-70ec60daef65\", \"t5_model.zip\", 114349609)"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"p4PBzQwrUGQ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_QZktplCUGVF"},"execution_count":null,"outputs":[]}]}